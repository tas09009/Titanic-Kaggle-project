{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name Sex_name  Sex   Age  \\\n",
      "0                            Braund, Mr. Owen Harris     male    0  22.0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   female    1  38.0   \n",
      "2                             Heikkinen, Miss. Laina   female    1  26.0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   female    1  35.0   \n",
      "4                           Allen, Mr. William Henry     male    0  35.0   \n",
      "\n",
      "   SibSp  Parch            Ticket     Fare Cabin Embarked_name  Embarked  \n",
      "0      1      0         A/5 21171   7.2500   NaN             S       3.0  \n",
      "1      1      0          PC 17599  71.2833   C85             C       1.0  \n",
      "2      0      0  STON/O2. 3101282   7.9250   NaN             S       3.0  \n",
      "3      1      0            113803  53.1000  C123             S       3.0  \n",
      "4      0      0            373450   8.0500   NaN             S       3.0  \n"
     ]
    }
   ],
   "source": [
    "# dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "# data = pd.read_csv(dataset_url)\n",
    "data1 = pd.read_csv('train.csv')\n",
    "print(data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
      "0            1         0       3    0  22.0      1      0   7.2500       3.0\n",
      "1            2         1       1    1  38.0      1      0  71.2833       1.0\n",
      "2            3         1       3    1  26.0      0      0   7.9250       3.0\n",
      "3            4         1       1    1  35.0      1      0  53.1000       3.0\n",
      "4            5         0       3    0  35.0      0      0   8.0500       3.0\n"
     ]
    }
   ],
   "source": [
    "# Pre-format DataFrame\n",
    "data = data1.drop(['Name', 'Ticket', 'Sex_name', 'Embarked_name', 'Cabin'], axis=1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "# 891 samples (rows) and 12 features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  714.000000   \n",
      "mean    446.000000    0.383838    2.308642    0.352413   29.699118   \n",
      "std     257.353842    0.486592    0.836071    0.477990   14.526497   \n",
      "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
      "25%     223.500000    0.000000    2.000000    0.000000   20.125000   \n",
      "50%     446.000000    0.000000    3.000000    0.000000   28.000000   \n",
      "75%     668.500000    1.000000    3.000000    1.000000   38.000000   \n",
      "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
      "\n",
      "            SibSp       Parch        Fare    Embarked  \n",
      "count  891.000000  891.000000  891.000000  889.000000  \n",
      "mean     0.523008    0.381594   32.204208    2.535433  \n",
      "std      1.102743    0.806057   49.693429    0.792088  \n",
      "min      0.000000    0.000000    0.000000    1.000000  \n",
      "25%      0.000000    0.000000    7.910400    2.000000  \n",
      "50%      0.000000    0.000000   14.454200    3.000000  \n",
      "75%      1.000000    0.000000   31.000000    3.000000  \n",
      "max      8.000000    6.000000  512.329200    3.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642    0.352413   29.699118   \n",
      "std     257.353842    0.486592    0.836071    0.477990   13.002015   \n",
      "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
      "25%     223.500000    0.000000    2.000000    0.000000   22.000000   \n",
      "50%     446.000000    0.000000    3.000000    0.000000   29.699118   \n",
      "75%     668.500000    1.000000    3.000000    1.000000   35.000000   \n",
      "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
      "\n",
      "            SibSp       Parch        Fare    Embarked  \n",
      "count  891.000000  891.000000  891.000000  891.000000  \n",
      "mean     0.523008    0.381594   32.204208    2.535433  \n",
      "std      1.102743    0.806057   49.693429    0.791197  \n",
      "min      0.000000    0.000000    0.000000    1.000000  \n",
      "25%      0.000000    0.000000    7.910400    2.000000  \n",
      "50%      0.000000    0.000000   14.454200    3.000000  \n",
      "75%      1.000000    0.000000   31.000000    3.000000  \n",
      "max      8.000000    6.000000  512.329200    3.000000  \n"
     ]
    }
   ],
   "source": [
    "#Age and Embarked are missing values. Need to fill them in with their mean values\n",
    "#this will replace all NaN values with the mean of the non null values\n",
    "\n",
    "mean_value=data['Age'].mean()\n",
    "data['Age']=data['Age'].fillna(mean_value)\n",
    "\n",
    "mean_value=data['Embarked'].mean()\n",
    "data['Embarked']=data['Embarked'].fillna(mean_value)\n",
    "\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Survived\n",
    "X = data.drop('Survived', axis=1)\n",
    "# Only 8 features (columns) remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.49692992e-17 -1.44703226e-16  3.74232480e-17  1.89611123e-16\n",
      "  3.49283648e-17  4.98976640e-17 -3.49283648e-17  8.48260288e-17]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    " \n",
    "print(X_train_scaled.mean(axis=0))\n",
    "# [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "\n",
    "print(X_train_scaled.std(axis=0))\n",
    "# [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07073273 -0.1549711  -0.01581775  0.1133593  -0.02248195  0.01449631\n",
      "  0.07546479  0.06245481]\n",
      "[0.977465   1.06416147 0.99503086 0.96507138 0.89306481 0.92643505\n",
      " 0.90556969 0.93164716]\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    " \n",
    "print(X_test_scaled.mean(axis=0))\n",
    "# [ 0.02776704  0.02592492 -0.03078587 -0.03137977 -0.00471876 -0.04413827\n",
    "#  -0.02414174 -0.00293273 -0.00467444 -0.10894663  0.01043391]\n",
    " \n",
    "print(X_test_scaled.std(axis=0))\n",
    "# [ 1.02160495  1.00135689  0.97456598  0.91099054  0.86716698  0.94193125\n",
    "#  1.03673213  1.03145119  0.95734849  0.83829505  1.0286218 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False))], 'verbose': False, 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True), 'randomforestregressor': RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False), 'standardscaler__copy': True, 'standardscaler__with_mean': True, 'standardscaler__with_std': True, 'randomforestregressor__bootstrap': True, 'randomforestregressor__ccp_alpha': 0.0, 'randomforestregressor__criterion': 'mse', 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__max_leaf_nodes': None, 'randomforestregressor__max_samples': None, 'randomforestregressor__min_impurity_decrease': 0.0, 'randomforestregressor__min_impurity_split': None, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__min_weight_fraction_leaf': 0.0, 'randomforestregressor__n_estimators': 100, 'randomforestregressor__n_jobs': None, 'randomforestregressor__oob_score': False, 'randomforestregressor__random_state': None, 'randomforestregressor__verbose': 0, 'randomforestregressor__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('randomforestregressor',\n",
       "                                        RandomForestRegressor(bootstrap=True,\n",
       "                                                              ccp_alpha=0.0,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features='auto',\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              max_samples=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_...\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=100,\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'randomforestregressor__max_depth': [None, 5, 3, 1],\n",
       "                         'randomforestregressor__max_features': ['auto', 'sqrt',\n",
       "                                                                 'log2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(pipeline, hyperparameters, cv=10)\n",
    " \n",
    "# Fit and tune model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestregressor__max_depth': 3, 'randomforestregressor__max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Conveniently, GridSearchCV from sklearn will automatically refit the model with the best set of hyperparameters using the entire training set.\n",
    "# This functionality is ON by default, but you can confirm it:\n",
    "\n",
    "print(clf.refit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict a new set of data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4626694040860574\n",
      "0.12728501679057533\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, y_pred))\n",
    "# between 0 and 1. 1 means perfect correlation\n",
    " \n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "# close to 0 as possible, less error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_regressor.pkl']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to a .pkl filePython\n",
    "joblib.dump(clf, 'rf_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10667013, 0.96684717, 0.10667013, 0.96684717, 0.64830675,\n",
       "       0.28665136, 0.10667013, 0.10667013, 0.10667013, 0.94315691,\n",
       "       0.64808482, 0.10667013, 0.96684717, 0.10667013, 0.39169015,\n",
       "       0.96684717, 0.10667013, 0.52348282, 0.10667013, 0.10951982,\n",
       "       0.11038006, 0.11038006, 0.35597591, 0.32730076, 0.93806526,\n",
       "       0.22165377, 0.92203344, 0.11038006, 0.32104424, 0.96297983,\n",
       "       0.33572531, 0.48190376, 0.48367496, 0.11311472, 0.10594286,\n",
       "       0.10667013, 0.68316454, 0.47686053, 0.10951982, 0.5232472 ,\n",
       "       0.34102002, 0.64487602, 0.96297983, 0.92382647, 0.91904105,\n",
       "       0.35323216, 0.69492905, 0.63654225, 0.10866007, 0.11038006,\n",
       "       0.3249175 , 0.1079328 , 0.23011092, 0.35657731, 0.10667013,\n",
       "       0.11038006, 0.22566602, 0.96297983, 0.36140413, 0.11311472,\n",
       "       0.10667013, 0.34367361, 0.10900506, 0.1178635 , 0.10951982,\n",
       "       0.37691391, 0.30002398, 0.12448255, 0.92278922, 0.10667013,\n",
       "       0.68635965, 0.47662491, 0.63906981, 0.95927601, 0.92665656,\n",
       "       0.11038006, 0.36042742, 0.10594286, 0.95923166, 0.10667013,\n",
       "       0.10951982, 0.24038692, 0.11662248, 0.93806526, 0.10667013,\n",
       "       0.35896413, 0.10667013, 0.10667013, 0.93806526, 0.35896413,\n",
       "       0.48005564, 0.10667013, 0.21353321, 0.3718671 , 0.92278922,\n",
       "       0.10667013, 0.33103497, 0.11150976, 0.30304118, 0.28359195,\n",
       "       0.11662248, 0.10951982, 0.47123694, 0.10667013, 0.96684717,\n",
       "       0.92278922, 0.95427369, 0.34654979, 0.66875443, 0.10667013,\n",
       "       0.87238553, 0.11038006, 0.10973234, 0.10667013, 0.21571288,\n",
       "       0.33064947, 0.11038006, 0.70724215, 0.52710214, 0.35613332,\n",
       "       0.31568577, 0.10667013, 0.95081535, 0.10667013, 0.11038006,\n",
       "       0.19810559, 0.12323542, 0.69492905, 0.10667013, 0.12448255,\n",
       "       0.25125859, 0.68997897, 0.10594286, 0.10667013, 0.10594286,\n",
       "       0.10667013, 0.10594286, 0.52667794, 0.95427369, 0.10667013,\n",
       "       0.96684717, 0.133148  , 0.22429274, 0.11038006, 0.37178223,\n",
       "       0.95923166, 0.11024098, 0.95968461, 0.1173257 , 0.40704225,\n",
       "       0.12003351, 0.36988703, 0.10667013, 0.96684717, 0.10594286,\n",
       "       0.10667013, 0.38262577, 0.93962395, 0.64830675, 0.10667013,\n",
       "       0.10667013, 0.10667013, 0.34344931, 0.96297983, 0.10667013,\n",
       "       0.25446669, 0.3636305 , 0.38283879, 0.95923166, 0.10594286,\n",
       "       0.96684717, 0.10594286, 0.95081495, 0.12935327, 0.32709542,\n",
       "       0.10866007, 0.10973234, 0.22524735, 0.92203344])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model from .pkl filePython (load the model again, simply use this function:)\n",
    "clf2 = joblib.load('rf_regressor.pkl')\n",
    " \n",
    "# Predict data set using loaded model\n",
    "clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
